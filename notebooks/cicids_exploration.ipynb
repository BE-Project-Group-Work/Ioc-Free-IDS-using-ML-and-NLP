{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e91995",
   "metadata": {},
   "source": [
    "## Step 1: Handling All Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d818d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing pipeline...\n",
      "Current time: 2025-09-20 10:31:33 IST\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP LIBRARIES AND DATA PATH ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# IMPORTANT: Put all 8 of your CICIDS2017 CSV files into one folder.\n",
    "# Then, update the path to that folder here.\n",
    "DATA_DIR = 'D:/IoC-Free IDS using ML and NLP/data/raw/CICIDS2017/'\n",
    "\n",
    "print(f\"Starting data processing pipeline...\")\n",
    "print(f\"Current time: {pd.Timestamp.now(tz='Asia/Kolkata').strftime('%Y-%m-%d %H:%M:%S %Z')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2011d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 8 CSV files to process in 'D:/IoC-Free IDS using ML and NLP/data/raw/CICIDS2017/'.\n",
      "--> Processing: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "--> Processing: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "--> Processing: Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "--> Processing: Monday-WorkingHours.pcap_ISCX.csv\n",
      "--> Processing: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "--> Processing: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "--> Processing: Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "--> Processing: Wednesday-workingHours.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 2. FIND AND PROCESS ALL CSV FILES IN A LOOP ---\n",
    "# Find all CSV file paths in the specified directory\n",
    "\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "print(f\"\\nFound {len(all_files)} CSV files to process in '{DATA_DIR}'.\")\n",
    "\n",
    "# This list will hold each cleaned DataFrame before we combine them\n",
    "\n",
    "list_of_cleaned_dfs = []\n",
    "\n",
    "for file_path in all_files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"--> Processing: {file_name}\")\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # a. Clean leading/trailing spaces from column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # b. Drop the IoC column ('Destination Port') for robust, behavioral detection\n",
    "    if 'Destination Port' in df.columns:\n",
    "        df.drop(columns = ['Destination Port'], inplace = True)\n",
    "    \n",
    "    # c. Handle potential duplicate column names by keeping the first instance\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    # d. Clean dirty data: replace infinities with NaN, then drop all rows with any nulls\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    # e. Add the fully cleaned DataFrame to our list\n",
    "    list_of_cleaned_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722342ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Combining all processed files into a single master DataFrame...\n",
      "Combination complete!\n"
     ]
    }
   ],
   "source": [
    "# --- 3. COMBINE INTO A SINGLE MASTER DATAFRAME ---\n",
    "print(\"\\n--> Combining all processed files into a single master DataFrame...\")\n",
    "master_df = pd.concat(list_of_cleaned_dfs, ignore_index = True)\n",
    "print(\"Combination complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95408dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Finalizing the master DataFrame...\n",
      "    - Standardized column names to snake_case.\n",
      "    - Dropped 8 zero-variance columns: ['bwd_psh_flags', 'bwd_urg_flags', 'fwd_avg_bytes/bulk', 'fwd_avg_packets/bulk', 'fwd_avg_bulk_rate', 'bwd_avg_bytes/bulk', 'bwd_avg_packets/bulk', 'bwd_avg_bulk_rate']\n"
     ]
    }
   ],
   "source": [
    "# --- 4. FINALIZE & STANDARDIZE THE MASTER DATAFRAME ---\n",
    "print(\"--> Finalizing the master DataFrame...\")\n",
    "\n",
    "# a. Standardize column names to snake_case (e.g., 'Flow Duration' -> 'flow_duration')\n",
    "master_df.columns = master_df.columns.str.replace(' ', '_').str.lower()\n",
    "print(\"    - Standardized column names to snake_case.\")\n",
    "\n",
    "# b. Remove any columns that have zero variance (i.e., the same value in every row)\n",
    "numeric_cols = master_df.select_dtypes(include=np.number).columns\n",
    "column_std = master_df[numeric_cols].std()\n",
    "zero_std_cols = column_std[column_std == 0].index.tolist()\n",
    "\n",
    "if zero_std_cols:\n",
    "    master_df.drop(columns=zero_std_cols, inplace=True)\n",
    "    print(f\"    - Dropped {len(zero_std_cols)} zero-variance columns: {zero_std_cols}\")\n",
    "else:\n",
    "    print(\"    - No zero-variance columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe127e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Complete! ---\n",
      "Final DataFrame Shape: 2,827,876 rows, 70 columns.\n",
      "\n",
      "Final DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2827876 entries, 0 to 2827875\n",
      "Data columns (total 70 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   flow_duration                int64  \n",
      " 1   total_fwd_packets            int64  \n",
      " 2   total_backward_packets       int64  \n",
      " 3   total_length_of_fwd_packets  int64  \n",
      " 4   total_length_of_bwd_packets  int64  \n",
      " 5   fwd_packet_length_max        int64  \n",
      " 6   fwd_packet_length_min        int64  \n",
      " 7   fwd_packet_length_mean       float64\n",
      " 8   fwd_packet_length_std        float64\n",
      " 9   bwd_packet_length_max        int64  \n",
      " 10  bwd_packet_length_min        int64  \n",
      " 11  bwd_packet_length_mean       float64\n",
      " 12  bwd_packet_length_std        float64\n",
      " 13  flow_bytes/s                 float64\n",
      " 14  flow_packets/s               float64\n",
      " 15  flow_iat_mean                float64\n",
      " 16  flow_iat_std                 float64\n",
      " 17  flow_iat_max                 int64  \n",
      " 18  flow_iat_min                 int64  \n",
      " 19  fwd_iat_total                int64  \n",
      " 20  fwd_iat_mean                 float64\n",
      " 21  fwd_iat_std                  float64\n",
      " 22  fwd_iat_max                  int64  \n",
      " 23  fwd_iat_min                  int64  \n",
      " 24  bwd_iat_total                int64  \n",
      " 25  bwd_iat_mean                 float64\n",
      " 26  bwd_iat_std                  float64\n",
      " 27  bwd_iat_max                  int64  \n",
      " 28  bwd_iat_min                  int64  \n",
      " 29  fwd_psh_flags                int64  \n",
      " 30  fwd_urg_flags                int64  \n",
      " 31  fwd_header_length            int64  \n",
      " 32  bwd_header_length            int64  \n",
      " 33  fwd_packets/s                float64\n",
      " 34  bwd_packets/s                float64\n",
      " 35  min_packet_length            int64  \n",
      " 36  max_packet_length            int64  \n",
      " 37  packet_length_mean           float64\n",
      " 38  packet_length_std            float64\n",
      " 39  packet_length_variance       float64\n",
      " 40  fin_flag_count               int64  \n",
      " 41  syn_flag_count               int64  \n",
      " 42  rst_flag_count               int64  \n",
      " 43  psh_flag_count               int64  \n",
      " 44  ack_flag_count               int64  \n",
      " 45  urg_flag_count               int64  \n",
      " 46  cwe_flag_count               int64  \n",
      " 47  ece_flag_count               int64  \n",
      " 48  down/up_ratio                int64  \n",
      " 49  average_packet_size          float64\n",
      " 50  avg_fwd_segment_size         float64\n",
      " 51  avg_bwd_segment_size         float64\n",
      " 52  fwd_header_length.1          int64  \n",
      " 53  subflow_fwd_packets          int64  \n",
      " 54  subflow_fwd_bytes            int64  \n",
      " 55  subflow_bwd_packets          int64  \n",
      " 56  subflow_bwd_bytes            int64  \n",
      " 57  init_win_bytes_forward       int64  \n",
      " 58  init_win_bytes_backward      int64  \n",
      " 59  act_data_pkt_fwd             int64  \n",
      " 60  min_seg_size_forward         int64  \n",
      " 61  active_mean                  float64\n",
      " 62  active_std                   float64\n",
      " 63  active_max                   int64  \n",
      " 64  active_min                   int64  \n",
      " 65  idle_mean                    float64\n",
      " 66  idle_std                     float64\n",
      " 67  idle_max                     int64  \n",
      " 68  idle_min                     int64  \n",
      " 69  label                        object \n",
      "dtypes: float64(24), int64(45), object(1)\n",
      "memory usage: 1.5+ GB\n",
      "\n",
      "Sample of new column names:\n",
      "['flow_duration', 'total_fwd_packets', 'total_backward_packets', 'total_length_of_fwd_packets', 'total_length_of_bwd_packets']\n",
      "\n",
      "✅ Success! Cleaned data has been saved to 'D:/IoC-Free IDS using ML and NLP/data/processed/cicids2017_cleaned_standardized.parquet'.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. VERIFY AND SAVE THE FINAL RESULT ---\n",
    "print(\"\\n--- Processing Complete! ---\")\n",
    "print(f\"Final DataFrame Shape: {master_df.shape[0]:,} rows, {master_df.shape[1]} columns.\")\n",
    "print(\"\\nFinal DataFrame Info:\")\n",
    "master_df.info()\n",
    "\n",
    "# Display a sample of the new standardized column names\n",
    "print(\"\\nSample of new column names:\")\n",
    "print(master_df.columns[:5].tolist())\n",
    "\n",
    "# Save the final, clean DataFrame to a fast-loading Parquet file\n",
    "output_filename = 'D:/IoC-Free IDS using ML and NLP/data/processed/cicids2017_cleaned_standardized.parquet'\n",
    "master_df.to_parquet(output_filename)\n",
    "print(f\"\\n✅ Success! Cleaned data has been saved to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c50d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Complete! ---\n",
      "Final DataFrame Shape: 2,827,876 rows, 70 columns.\n",
      "\n",
      "Final DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2827876 entries, 0 to 2827875\n",
      "Data columns (total 70 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   flow_duration                int64  \n",
      " 1   total_fwd_packets            int64  \n",
      " 2   total_backward_packets       int64  \n",
      " 3   total_length_of_fwd_packets  int64  \n",
      " 4   total_length_of_bwd_packets  int64  \n",
      " 5   fwd_packet_length_max        int64  \n",
      " 6   fwd_packet_length_min        int64  \n",
      " 7   fwd_packet_length_mean       float64\n",
      " 8   fwd_packet_length_std        float64\n",
      " 9   bwd_packet_length_max        int64  \n",
      " 10  bwd_packet_length_min        int64  \n",
      " 11  bwd_packet_length_mean       float64\n",
      " 12  bwd_packet_length_std        float64\n",
      " 13  flow_bytes/s                 float64\n",
      " 14  flow_packets/s               float64\n",
      " 15  flow_iat_mean                float64\n",
      " 16  flow_iat_std                 float64\n",
      " 17  flow_iat_max                 int64  \n",
      " 18  flow_iat_min                 int64  \n",
      " 19  fwd_iat_total                int64  \n",
      " 20  fwd_iat_mean                 float64\n",
      " 21  fwd_iat_std                  float64\n",
      " 22  fwd_iat_max                  int64  \n",
      " 23  fwd_iat_min                  int64  \n",
      " 24  bwd_iat_total                int64  \n",
      " 25  bwd_iat_mean                 float64\n",
      " 26  bwd_iat_std                  float64\n",
      " 27  bwd_iat_max                  int64  \n",
      " 28  bwd_iat_min                  int64  \n",
      " 29  fwd_psh_flags                int64  \n",
      " 30  fwd_urg_flags                int64  \n",
      " 31  fwd_header_length            int64  \n",
      " 32  bwd_header_length            int64  \n",
      " 33  fwd_packets/s                float64\n",
      " 34  bwd_packets/s                float64\n",
      " 35  min_packet_length            int64  \n",
      " 36  max_packet_length            int64  \n",
      " 37  packet_length_mean           float64\n",
      " 38  packet_length_std            float64\n",
      " 39  packet_length_variance       float64\n",
      " 40  fin_flag_count               int64  \n",
      " 41  syn_flag_count               int64  \n",
      " 42  rst_flag_count               int64  \n",
      " 43  psh_flag_count               int64  \n",
      " 44  ack_flag_count               int64  \n",
      " 45  urg_flag_count               int64  \n",
      " 46  cwe_flag_count               int64  \n",
      " 47  ece_flag_count               int64  \n",
      " 48  down/up_ratio                int64  \n",
      " 49  average_packet_size          float64\n",
      " 50  avg_fwd_segment_size         float64\n",
      " 51  avg_bwd_segment_size         float64\n",
      " 52  fwd_header_length.1          int64  \n",
      " 53  subflow_fwd_packets          int64  \n",
      " 54  subflow_fwd_bytes            int64  \n",
      " 55  subflow_bwd_packets          int64  \n",
      " 56  subflow_bwd_bytes            int64  \n",
      " 57  init_win_bytes_forward       int64  \n",
      " 58  init_win_bytes_backward      int64  \n",
      " 59  act_data_pkt_fwd             int64  \n",
      " 60  min_seg_size_forward         int64  \n",
      " 61  active_mean                  float64\n",
      " 62  active_std                   float64\n",
      " 63  active_max                   int64  \n",
      " 64  active_min                   int64  \n",
      " 65  idle_mean                    float64\n",
      " 66  idle_std                     float64\n",
      " 67  idle_max                     int64  \n",
      " 68  idle_min                     int64  \n",
      " 69  label                        object \n",
      "dtypes: float64(24), int64(45), object(1)\n",
      "memory usage: 1.5+ GB\n",
      "\n",
      "Sample of new column names:\n",
      "['flow_duration', 'total_fwd_packets', 'total_backward_packets', 'total_length_of_fwd_packets', 'total_length_of_bwd_packets']\n",
      "\n",
      "✅ Success! Cleaned data has been saved to 'D:/IoC-Free IDS using ML and NLP/data/processed/cicids2017_cleaned_standardized.csv'.\n"
     ]
    }
   ],
   "source": [
    "# The CSV file is generated for personal reference and out project will use the cleaned parquet as it is faster ans more efficient.\n",
    "\n",
    "print(\"\\n--- Processing Complete! ---\")\n",
    "print(f\"Final DataFrame Shape: {master_df.shape[0]:,} rows, {master_df.shape[1]} columns.\")\n",
    "print(\"\\nFinal DataFrame Info:\")\n",
    "master_df.info()\n",
    "\n",
    "# Display a sample of the new standardized column names\n",
    "print(\"\\nSample of new column names:\")\n",
    "print(master_df.columns[:5].tolist())\n",
    "\n",
    "# Save the final, clean DataFrame to a fast-loading Parquet file\n",
    "output_filename = 'D:/IoC-Free IDS using ML and NLP/data/processed/cicids2017_cleaned_standardized.csv'\n",
    "master_df.to_csv(output_filename)\n",
    "print(f\"\\n✅ Success! Cleaned data has been saved to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177fce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "flow_duration                  0\n",
       "total_fwd_packets              0\n",
       "total_backward_packets         0\n",
       "total_length_of_fwd_packets    0\n",
       "                              ..\n",
       "idle_mean                      0\n",
       "idle_std                       0\n",
       "idle_max                       0\n",
       "idle_min                       0\n",
       "label                          0\n",
       "Length: 71, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = pd.read_csv(\"D:/IoC-Free IDS using ML and NLP/data/processed/cicids2017_cleaned_standardized.csv\")\n",
    "# df1.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
